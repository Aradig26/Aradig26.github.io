{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13280272,"sourceType":"datasetVersion","datasetId":8416363},{"sourceId":599663,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":449241,"modelId":465631}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nprint(\"CUDA available:\", torch.cuda.is_available())\n\n# ================================\n# Step 1: Upgrade pip, setuptools, and wheel\n# ================================\n!pip install --upgrade pip setuptools wheel  # Upgrade pip, setuptools, and wheel\n\n# ================================\n# Step 2: Uninstall conflicting packages\n# ================================\n!pip uninstall -y protobuf google-api-core google-cloud-bigquery google-cloud-translate google-ai-generativelanguage rich\n\n# ================================\n# Step 3: Install compatible versions of dependencies\n# ================================\n!pip install protobuf==3.19.5 google-api-core==2.15.0 google-cloud-bigquery==3.24.0 google-cloud-translate==3.12.1 google-ai-generativelanguage==0.6.15 rich==12.4.4\n\n# ================================\n# Step 4: Install torch_xla for TPU support\n# ================================\n!pip install torch_xla\n\n# ================================\n# Step 5: Install YOLO and other required libraries\n# ================================\n!pip install -U \"ultralytics>=8.3.0\" torch torchvision torchaudio pyyaml tqdm opencv-python matplotlib \\\n    protobuf<6.0.0 \\\n    numpy<2.1.0 \\\n    google-api-core>=2.15.0,<3.0.0 \\\n    pandas-gbq>=0.29.1 \\\n    google-cloud-bigquery-storage>=2.30.0,<3.0.0 \\\n    rich<14 \\\n    scikit-learn>=1.3.1,<2.0.0 \\\n    \"tensorflow-cpu==2.18.0\"\n\n# ================================\n# Step 6: Install ONNX and ONNX Runtime\n# ================================\n!pip install onnx onnxruntime\n\nprint(\"done\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-06T18:02:45.553735Z","iopub.execute_input":"2025-10-06T18:02:45.554335Z","iopub.status.idle":"2025-10-06T18:02:56.459819Z","shell.execute_reply.started":"2025-10-06T18:02:45.554312Z","shell.execute_reply":"2025-10-06T18:02:56.458602Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (80.9.0)\nRequirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\nFound existing installation: protobuf 6.32.1\nUninstalling protobuf-6.32.1:\n  Successfully uninstalled protobuf-6.32.1\n\u001b[33mWARNING: Skipping google-api-core as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping google-cloud-bigquery as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping google-cloud-translate as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping google-ai-generativelanguage as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping rich as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting protobuf==3.19.5\n  Using cached protobuf-3.19.5-py2.py3-none-any.whl.metadata (828 bytes)\nCollecting google-api-core==2.15.0\n  Downloading google_api_core-2.15.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting google-cloud-bigquery==3.24.0\n  Downloading google_cloud_bigquery-3.24.0-py2.py3-none-any.whl.metadata (8.9 kB)\nCollecting google-cloud-translate==3.12.1\n  Using cached google_cloud_translate-3.12.1-py2.py3-none-any.whl.metadata (5.2 kB)\nCollecting google-ai-generativelanguage==0.6.15\n  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\nCollecting rich==12.4.4\n  Using cached rich-12.4.4-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core==2.15.0) (1.70.0)\nRequirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core==2.15.0) (2.40.3)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core==2.15.0) (2.32.4)\nRequirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery==3.24.0) (2.4.3)\nRequirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery==3.24.0) (2.7.2)\nRequirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery==3.24.0) (25.0)\nRequirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery==3.24.0) (2.9.0.post0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-translate==3.12.1) (1.26.1)\nINFO: pip is looking at multiple versions of google-ai-generativelanguage to determine which version is compatible with other requirements. This could take a while.\n\u001b[31mERROR: Cannot install google-ai-generativelanguage==0.6.15, google-api-core==2.15.0, google-cloud-translate==3.12.1 and protobuf==3.19.5 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n\u001b[0m\nThe conflict is caused by:\n    The user requested protobuf==3.19.5\n    google-api-core 2.15.0 depends on protobuf!=3.20.0, !=3.20.1, !=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <5.0.0.dev0 and >=3.19.5\n    google-cloud-translate 3.12.1 depends on protobuf!=3.20.0, !=3.20.1, !=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <5.0.0dev and >=3.19.5\n    google-ai-generativelanguage 0.6.15 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n\nTo fix this you could try to:\n1. loosen the range of package versions you've specified\n2. remove package versions to allow pip to attempt to solve the dependency conflict\n\n\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: torch_xla in /usr/local/lib/python3.11/dist-packages (2.8.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from torch_xla) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_xla) (1.26.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from torch_xla) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_xla) (2.32.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_xla) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_xla) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_xla) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_xla) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_xla) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_xla) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_xla) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_xla) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_xla) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_xla) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_xla) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla) (2025.6.15)\n/bin/bash: line 1: 6.0.0: No such file or directory\nRequirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.18.0)\nRequirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.23.0)\nRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\nCollecting protobuf>=4.25.1 (from onnx)\n  Using cached protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\nRequirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.0)\nRequirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->onnx) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->onnx) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->onnx) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->onnx) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->onnx) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22->onnx) (2.4.1)\nRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22->onnx) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22->onnx) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22->onnx) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22->onnx) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22->onnx) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\nUsing cached protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\nInstalling collected packages: protobuf\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-videointelligence 2.16.2 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1, which is not installed.\ngoogle-cloud-vision 3.10.2 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1, which is not installed.\ngoogle-cloud-functions 1.20.4 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1, which is not installed.\ngoogle-cloud-resource-manager 1.14.2 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1, which is not installed.\ngoogle-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, which is not installed.\ngoogle-generativeai 0.8.5 requires google-api-core, which is not installed.\ngoogle-cloud-datastore 2.21.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0, which is not installed.\ngoogle-cloud-iam 2.19.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1, which is not installed.\nflax 0.10.6 requires rich>=11.1, which is not installed.\ngoogle-cloud-language 2.17.2 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1, which is not installed.\ngoogle-cloud-spanner 3.55.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0, which is not installed.\ngoogle-cloud-bigquery-connection 1.18.3 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1, which is not installed.\ngoogle-cloud-dataproc 5.20.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1, which is not installed.\ngoogle-cloud-aiplatform 1.99.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1, which is not installed.\ngoogle-cloud-aiplatform 1.99.0 requires google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nbigframes 2.8.0 requires rich<14,>=12.4.4, which is not installed.\ngoogle-cloud-firestore 2.21.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.0, which is not installed.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.32.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-6.32.1\ndone\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip uninstall -y wandb\n\nimport os\nimport torch\nfrom pathlib import Path\nfrom ultralytics import YOLO\nimport torch.distributed as dist\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport torch.nn as nn\n\n# ============================================================\n# Base Paths\n# ============================================================\nBASE_DIR = Path(\"/kaggle/input\")\nWORKING_DIR = Path(\"/kaggle/working\")\nRUNS_DIR = WORKING_DIR / \"runs\" / \"detect\"\n\nDATASET_PATH = BASE_DIR / \"reefscape\" / \"data.yaml\"\nMODEL_PATH = \"/kaggle/input/yolo11n/other/default/1/yolo11n.pt\"\n\n# ============================================================\n# Helpers\n# ============================================================\ndef print_header(text):\n    print(\"\\n\" + \"=\" * 65)\n    print(f\"🚀 {text}\")\n    print(\"=\" * 65)\n\n# ============================================================\n# DDP Initialization\n# ============================================================\ndef setup_ddp(rank, world_size):\n    \"\"\"Initialize Distributed Data Parallel\"\"\"\n    # Set master node environment variables (use 'localhost' for a single-node setup)\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\n        backend='nccl', \n        rank=rank, \n        world_size=world_size\n    )\n\ndef cleanup_ddp():\n    \"\"\"Clean up after DDP\"\"\"\n    dist.destroy_process_group()\n\n# ============================================================\n# Training Function for Distributed Data Parallel (DDP)\n# ============================================================\ndef train_phase(rank, world_size, name, base_model, data, epochs, batch, imgsz=640, lr0=None):\n    \"\"\"Runs or resumes a YOLO training phase with DDP.\"\"\"\n    print_header(f\"Starting Phase: {name}\")\n\n    project_dir = RUNS_DIR / name\n    last_weights = project_dir / \"weights\" / \"last.pt\"\n\n    # If session expired, resume automatically\n    if last_weights.exists():\n        print(f\"Resuming from previous session: {last_weights}\")\n        model = YOLO(str(last_weights))\n    else:\n        print(f\"Starting new training run: {name}\")\n        model = YOLO(base_model)\n\n    # Set up DDP\n    model = model.model.to(rank)  # Move model to the correct device\n    model = DDP(model, device_ids=[rank])\n\n    args = dict(\n        data=str(data),\n        epochs=epochs,\n        batch=batch,\n        imgsz=imgsz,\n        device=rank,  # Use the correct GPU for this process\n        name=name,\n        project=str(RUNS_DIR.parent),\n        save=True,\n        workers=8,\n        distributed_rank=rank,\n        # No caching here\n    )\n\n    if lr0:\n        args[\"lr0\"] = lr0\n\n    # Start training\n    model.train(**args)\n    print(f\"✅ Phase '{name}' complete!\")\n\n# ============================================================\n# Main Training Pipeline with DDP\n# ============================================================\ndef main(rank, world_size):\n    setup_ddp(rank, world_size)  # Set up DDP for this rank\n    \n    # -----------------------\n    # Phase 1: General Train\n    # -----------------------\n    train_phase(\n        rank=rank,\n        world_size=world_size,\n        name=\"coral_algae_phase1\",\n        base_model=MODEL_PATH,\n        data=DATASET_PATH,\n        epochs=150,\n        batch=64,\n        imgsz=640\n    )\n\n    # -----------------------\n    # Phase 2: Fine-Tune\n    # -----------------------\n    phase1_best = RUNS_DIR / \"coral_algae_phase1\" / \"weights\" / \"best.pt\"\n    fine_tune_base = str(phase1_best if phase1_best.exists() else MODEL_PATH)\n\n    train_phase(\n        rank=rank,\n        world_size=world_size,\n        name=\"coral_algae_finetune\",\n        base_model=fine_tune_base,\n        data=DATASET_PATH,\n        epochs=50,\n        batch=8,\n        imgsz=640,\n        lr0=0.001\n    )\n\n    cleanup_ddp()  # Clean up DDP processes\n    print_header(\"✅ All training phases complete!\")\n\n# ============================================================\n# Run the Script for Distributed Training\n# ============================================================\nif __name__ == \"__main__\":\n    world_size = 2  # Number of GPUs (2 in this case)\n\n    # Set environment variables for distributed training\n    os.environ[\"WORLD_SIZE\"] = str(world_size)\n    \n    # The rank will be set based on the process number (you may set it manually or use a launcher like torchrun)\n    rank = int(os.environ[\"RANK\"]) if \"RANK\" in os.environ else 0  # Default rank if not set\n\n    # Call the main function\n    main(rank, world_size)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}